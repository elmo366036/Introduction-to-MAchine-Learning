{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.1.1\n",
    "\n",
    "# modify feat_info['missing_or_unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONE\n",
    "\n",
    "# Identify missing or unknown data values and convert them to NaNs.\n",
    "\n",
    "# In this code block we will create a new column in feat_info that will contain\n",
    "#   the processed missing values\n",
    "# This is crude but it works and since there are only 85 rows it is fast. \n",
    "feat_info['missing'] = feat_info['missing_or_unknown'].copy()\n",
    "characters = ['', 'X', 'XX']\n",
    "\n",
    "# iterate through feat_info row by row\n",
    "for idx in range(feat_info.shape[0]):\n",
    "    \n",
    "    # create a list from 'missing' at row idx and remove the brackets\n",
    "    temp_list  = feat_info.iloc[idx]['missing'][1:-1].split(sep=',')                                \n",
    "    temp_list2 = []                   \n",
    "    for c in temp_list:               # need to iterate through the original list \n",
    "        if c in characters:           # if 'X' or 'XX', add to new list as is\n",
    "            temp_list2.append(c)\n",
    "        else:                         # if not, it's a number and needs\n",
    "            temp_list2.append(int(c)) #    to be converted to int before added to new list\n",
    "    temp_list = temp_list2\n",
    "    \n",
    "    feat_info.at[idx, 'missing'] = temp_list\n",
    "\n",
    "#feat_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to apply this to the data set\n",
    "\n",
    "# algo\n",
    "#   for each col in azdias:\n",
    "#      look for entries corresponding to feat_col.at[col, missing]\n",
    "#      if there are any, replace them with nan\n",
    "\n",
    "azdias_cols = azdias.columns\n",
    "\n",
    "for col in azdias_cols:\n",
    "    temp_feature = azdias[col].copy()\n",
    "    temp_missing = feat_info.loc[feat_info['attribute'] == col]['missing'].array\n",
    "    temp_feature[temp_feature.isin(temp_missing[0])] = np.nan\n",
    "    azdias[col] = temp_feature\n",
    "\n",
    "azdias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an assessment of how much missing data there is in each column of the\n",
    "# dataset.\n",
    "\n",
    "missing_col_data = {}\n",
    "\n",
    "for col in azdias.columns:        \n",
    "    missing_col_data[col] = azdias[col].isnull().sum() \n",
    "\n",
    "missing_features = pd.DataFrame.from_dict(missing_col_data, orient='index')\n",
    "missing_features.rename(columns={0:'# NaNs'}, inplace=True)\n",
    "missing_features.sort_values(by='# NaNs', ascending=False, inplace=True)\n",
    "missing_features['% NaNs'] = 100 * missing_features['# NaNs'] / azdias.shape[0]\n",
    "\n",
    "missing_features['# NaNs'].hist(bins=85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the outlier columns from the dataset. (You'll perform other data\n",
    "# engineering tasks such as re-encoding and imputation later.)\n",
    "# We will use 33$ NaNs as a threshold\n",
    "col_threshold = 33\n",
    "features_to_drop = missing_features[missing_features['% NaNs'] > col_threshold].index.tolist()\n",
    "azdias.drop(features_to_drop, axis=1, inplace=True)\n",
    "azdias.head()\n",
    "\n",
    "# This works. rerun the entire book up to this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much data is missing in each row of the dataset?\n",
    "\n",
    "\n",
    "# In this code block we will create a new column in azdias that will contain\n",
    "#   the number of missing values \n",
    "azdias['# NaNs'] = azdias.isnull().sum(axis=1)\n",
    "azdias['% NaNs'] = 100 * azdias['# NaNs'] / (azdias.shape[1] - 1)\n",
    "azdias_sorted = azdias.sort_values(by='# NaNs', axis=0, ascending=False)\n",
    "azdias_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to divide the data into two subsets based on the number of missing\n",
    "# values in each row.\n",
    "\n",
    "# from the histogram we can see that there are two sets of data pertaining to \n",
    "#   NaNs. The groups are split around 5% missing data. We will split accordingly.\n",
    "#   Note that most of the data has ver little NaNs.\n",
    "\n",
    "row_nan_threshold = 5\n",
    "azdias_lower = azdias[azdias['% NaNs'] < row_nan_threshold]\n",
    "azdias_upper = azdias[azdias['% NaNs'] > row_nan_threshold]\n",
    "\n",
    "print (azdias_lower.shape, azdias_lower['% NaNs'].max())\n",
    "print (azdias_upper.shape, azdias_upper['% NaNs'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the distribution of values for at least five columns where there are\n",
    "# no or few missing values, between the two subsets.\n",
    "\n",
    "# we need to identify some columns in each data set that does not have any NaNs.\n",
    "# there are 24 features that do not have NaNs in either data set.\n",
    "\n",
    "azdias_upper_notna = azdias_upper[azdias_upper.columns[~azdias_upper.isnull().any()]].columns.values.tolist()\n",
    "azdias_lower_notna = azdias_lower[azdias_lower.columns[~azdias_lower.isnull().any()]].columns.values.tolist()\n",
    "\n",
    "azdias_notna = list(set(azdias_upper_notna) & set(azdias_lower_notna)) \n",
    "azdias_notna.remove('# NaNs')\n",
    "azdias_notna.remove('% NaNs')\n",
    "azdias_lower.drop('# NaNs', axis=1, inplace=True)\n",
    "azdias_lower.drop('% NaNs', axis=1, inplace=True)\n",
    "\n",
    "print(azdias_notna[:5])\n",
    "print(len(azdias_notna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to get a view of feat_info without the features that we dropped earlier\n",
    "feat_info_reduced = feat_info.copy()\n",
    "feat_info_reduced = feat_info_reduced[~feat_info_reduced['attribute'].isin(features_to_drop)]\n",
    "feat_info_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess categorical variables: which are binary, which are multi-level, and\n",
    "# which one needs to be re-encoded?\n",
    "categorical = feat_info_reduced[feat_info['type']=='categorical']['attribute'].tolist()\n",
    "\n",
    "for feature in categorical: \n",
    "    values = azdias_lower[feature].unique()\n",
    "    print(feature, values)\n",
    "    \n",
    "# Re-encode categorical variable(s) to be kept in the analysis.\n",
    "\n",
    "# We'll loop through the categorical features and one encode some of them\n",
    "# We will make a copy of azdias_lower and use it\n",
    "\n",
    "azdias_preprocessed = azdias_lower.copy()\n",
    "\n",
    "for feature in categorical: \n",
    "    values = azdias_preprocessed[feature].unique()\n",
    "    if (values.size > 2) | (type(values[0]) == str):                          # if string or multi-level\n",
    "        X = pd.get_dummies(azdias_preprocessed[feature], prefix=[feature])    # one hot encode\n",
    "        azdias_preprocessed[X.columns] = X                                    # concatenate\n",
    "        azdias_preprocessed.drop(feature, axis=1, inplace=True)               # drop the original feature\n",
    "\n",
    "print(azdias_preprocessed.columns.size)\n",
    "print(azdias_preprocessed.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the mixed feature types\n",
    "mixed = feat_info_reduced[feat_info['type']=='mixed']['attribute'].tolist()\n",
    "\n",
    "PRAEGENDE_JUGENDJAHRE_map = {0:[0,0],   1:[1,1], 2:[2,1],\n",
    "                             3:[1,2],   4:[2,2], 5:[1,3],\n",
    "                             6:[2,3],   7:[2,3], 8:[1,4],\n",
    "                             9:[2,4],  10:[1,5],11:[2,5],\n",
    "                             12:[1,5], 13:[2,5],14:[1,6],\n",
    "                             15:[2,6]\n",
    "                            }\n",
    "# We will need to address the NaNs. Lets set them to 0\n",
    "azdias_preprocessed['PRAEGENDE_JUGENDJAHRE'].fillna(value=0, inplace=True)\n",
    "\n",
    "# We can create two new features and map them using PRAEGENDE_JUGENDJAHRE_map\n",
    "azdias_preprocessed['PRAEGENDE_JUGENDJAHRE_movement'] = \\\n",
    "     azdias_preprocessed['PRAEGENDE_JUGENDJAHRE'].map(PRAEGENDE_JUGENDJAHRE_map).map(lambda x: x[0])\n",
    "azdias_preprocessed['PRAEGENDE_JUGENDJAHRE_decade'] = \\\n",
    "     azdias_preprocessed['PRAEGENDE_JUGENDJAHRE'].map(PRAEGENDE_JUGENDJAHRE_map).map(lambda x: x[1])\n",
    "\n",
    "# Since we are not able to completely split E and W, we will keep 'PRAEGENDE_JUGENDJAHRE'\n",
    "#   and not remove it\n",
    "\n",
    "# Investigate \"CAMEO_INTL_2015\" and engineer two new variables.\n",
    "\n",
    "# The range for this is ['51' '24' '43' '54' '22' '14' '13' '15' '34' '55' '12' \n",
    "#      '41' '25' '23' '31' '52' '35' '45' '33' '44' '32' nan]\n",
    "# We have to review the Data_Dictionary to make sense of it.\n",
    "# -1 is unknown. We will set the NaNs we created earlier to -1.  \n",
    "# The coding for \"wealth\" and \"life stage from the dictionary is\n",
    "#    houshold: unknown=-x1 and XX, Wealthy=1x, Properous=2x, Confortable=3x, Less Affluent=4x, Poorer=5x \n",
    "#    life stage: unknown=x0, Pre-Fam=x1, Young=x2, Family=x3, Old Family=x4, Elders=x5 \n",
    "# \n",
    "# We can simply split the 10's from the 1's for the new features.\n",
    "\n",
    "# We need to address the NaNs. Let's set them to a value that we can split in which\n",
    "#   both the ten's and one's are not used. We'll use 99.\n",
    "azdias_preprocessed['CAMEO_INTL_2015'].fillna(value=99, inplace=True)\n",
    "\n",
    "# We now need to split the values. One way to do this is to convert the series in to strings\n",
    "#   and use .str to slice them. Then we turn them back into ints. \n",
    "azdias_preprocessed['CAMEO_INTL_2015']            = azdias_preprocessed['CAMEO_INTL_2015'].astype(str)\n",
    "azdias_preprocessed['CAMEO_INTL_2015_wealth']     = azdias_preprocessed['CAMEO_INTL_2015'].str[0].astype(int)\n",
    "azdias_preprocessed['CAMEO_INTL_2015_lifestage']  = azdias_preprocessed['CAMEO_INTL_2015'].str[1].astype(int)\n",
    "azdias_preprocessed.drop('CAMEO_INTL_2015', axis=1, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
